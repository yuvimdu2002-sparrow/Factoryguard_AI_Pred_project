# ğŸ­ FactoryGuard AI â€“ Machine Failure Prediction

FactoryGuard AI is a **machine learningâ€“based predictive maintenance project** that predicts whether an industrial robotic arm will fail within the **next 24 hours** using sensor data.  
The project focuses on **imbalanced data handling**, **high-precision prediction**, and **model explainability**.

---

## ğŸ¯ Project Objective

- Predict machine failure within the next 24 hours
- Handle highly imbalanced industrial data
- Reduce false alarms by maintaining high precision
- Explain model predictions using SHAP
- Build an end-to-end ML pipeline

---

## ğŸ“Š Dataset Overview

**Sensor Features:**
- Temperature (Â°C)
- Vibration (RMS mm/s)
- Pressure (bar)
- RPM
- Load percentage
- Error count
- Maintenance history
- Humidity

**Target Variable:**
- `failure_in_next_24h`
  - `1` â†’ Failure expected within 24 hours
  - `0` â†’ No failure

## ğŸ§± Project Structure
FactoryGuard-AI_Pred_project/
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/
â”‚ â”‚ â””â”€â”€ factoryguard_synthetic_500.csv
â”‚ â””â”€â”€ processed/
â”‚ â””â”€â”€ features_engineering_output.csv
â”œâ”€â”€ model/
â”‚ â”œâ”€â”€ baseline_logistic_gridsearch.joblib
â”‚ â”œâ”€â”€ features_engineering.joblib
â”‚ â””â”€â”€ xgboost_tuned.joblib
â”œâ”€â”€ notebook/
â”‚ â””â”€â”€ EDA.ipynb
â”œâ”€â”€ report/
â”‚ â”œâ”€â”€ feature_selection_report.csv
â”‚ â”œâ”€â”€ shap_global_feature_importance.png
â”‚ â””â”€â”€ shap_local_failure_explanation.png
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ feature_engineering.py
â”‚ â”œâ”€â”€ feature_selection.py
â”‚ â”œâ”€â”€ model_evaluation.py
â”‚ â”œâ”€â”€ Shap.py
â”‚ â”œâ”€â”€ train_baseline_logreg.py
â”‚ â””â”€â”€ train_xgboost_optuna.py
â”œâ”€â”€ .gitattributes
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

---

## ğŸ”§ Feature Engineering

- Rolling Mean (1h, 6h, 12h)
- Rolling Standard Deviation
- Exponential Moving Average (EMA)
- Lag features (t-1, t-2)

Target label:


Unnecessary features were removed using feature selection techniques.

---

## ğŸ¯ Feature Selection Methods

- Filter Method (ANOVA F-test)
- Wrapper Method (RFE â€“ Recursive Feature Elimination)
- Embedded Method (Random Forest Feature Importance)

---

## ğŸ¤– Models Used

### 1ï¸âƒ£ Logistic Regression (Baseline)
- `class_weight = "balanced"`
- Hyperparameter tuning using GridSearchCV
- Evaluation metric: **PR-AUC**

### 2ï¸âƒ£ XGBoost (Final Model)
- Hyperparameter tuning using Optuna
- Handles class imbalance using `scale_pos_weight`
- Optimized for high precision

---

## ğŸ“ˆ Model Evaluation

- Primary Metric: **PR-AUC (Precisionâ€“Recall AUC)**
- Test-set evaluation only
- Custom threshold selected for â‰¥90% precision
- Classification report generated

---

## ğŸ” Model Explainability (SHAP)

- **Global Explanation:** Important features affecting failures
- **Local Explanation:** Reason behind individual failure predictions

Generated outputs:
- `shap_global_feature_importance.png`
- `shap_local_failure_explanation.png`

---

## ğŸ› ï¸ Installation

```bash
pip install -r requirements.txt


## ğŸ§± Project Structure

